{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b79129c9",
   "metadata": {},
   "source": [
    "# Polars: The Ultimate All-in-One Workbook\n",
    "\n",
    "**A complete, beginner-friendly guide to Polars for data analysis.**\n",
    "\n",
    "This notebook demonstrates the most important features of Polars, using real datasets from the project. It is written for both technical and non-technical users. All steps are explained in plain English, with clear code and outputs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74328b7",
   "metadata": {},
   "source": [
    "## 1. Introduction to Polars and Loading Data\n",
    "\n",
    "Polars is a fast, modern DataFrame library for data analysis in Python. Let's start by importing Polars and loading some datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7fefab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:07.922605Z",
     "iopub.status.busy": "2025-04-21T17:01:07.921955Z",
     "iopub.status.idle": "2025-04-21T17:01:08.328230Z",
     "shell.execute_reply": "2025-04-21T17:01:08.323679Z"
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load a sample of available datasets\n",
    "clients = pl.read_csv('../datasets/clients.csv')\n",
    "transactions = pl.read_csv('../datasets/transactions.csv')\n",
    "assets = pl.read_parquet('../datasets/assets.parquet')\n",
    "portfolio = pl.read_csv('../datasets/portfolio_performance.csv')\n",
    "print('Clients:', clients.shape)\n",
    "print('Transactions:', transactions.shape)\n",
    "print('Assets:', assets.shape)\n",
    "print('Portfolio:', portfolio.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9adb36",
   "metadata": {},
   "source": [
    "## 2. Exploring DataFrames: The Basics\n",
    "\n",
    "Let's look at the structure of our datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a29a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:08.343970Z",
     "iopub.status.busy": "2025-04-21T17:01:08.342792Z",
     "iopub.status.idle": "2025-04-21T17:01:08.364568Z",
     "shell.execute_reply": "2025-04-21T17:01:08.361121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show the first few rows of each DataFrame\n",
    "print('Clients sample:')\n",
    "print(clients.head())\n",
    "print('Transactions sample:')\n",
    "print(transactions.head())\n",
    "print('Assets sample:')\n",
    "print(assets.head())\n",
    "print('Portfolio sample:')\n",
    "print(portfolio.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f30e6",
   "metadata": {},
   "source": [
    "### DataFrame Info and Summary\n",
    "\n",
    "Polars makes it easy to see the columns, data types, and summary statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d2bb2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:08.372242Z",
     "iopub.status.busy": "2025-04-21T17:01:08.371269Z",
     "iopub.status.idle": "2025-04-21T17:01:08.443462Z",
     "shell.execute_reply": "2025-04-21T17:01:08.437834Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Clients columns:', clients.columns)\n",
    "print('Transactions dtypes:', transactions.dtypes)\n",
    "print('Assets summary:')\n",
    "print(assets.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b161b",
   "metadata": {},
   "source": [
    "## 3. Data Selection and Filtering\n",
    "\n",
    "Let's select specific columns and filter rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea62a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:08.460318Z",
     "iopub.status.busy": "2025-04-21T17:01:08.458350Z",
     "iopub.status.idle": "2025-04-21T17:01:08.497650Z",
     "shell.execute_reply": "2025-04-21T17:01:08.496071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select columns\n",
    "print(clients.select(['client_id', 'name']))\n",
    "\n",
    "# Filter: Show transactions above a threshold\n",
    "large_tx = transactions.filter(pl.col('amount') > 10000)\n",
    "print('Large transactions:')\n",
    "print(large_tx.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a3085",
   "metadata": {},
   "source": [
    "## 4. Grouping and Aggregation\n",
    "\n",
    "Group data to get insights, such as total transactions per client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04ee3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:08.519254Z",
     "iopub.status.busy": "2025-04-21T17:01:08.518749Z",
     "iopub.status.idle": "2025-04-21T17:01:08.555513Z",
     "shell.execute_reply": "2025-04-21T17:01:08.553740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Total transaction amount per client\n",
    "tx_per_client = transactions.group_by('client_id').agg(pl.col('amount').sum().alias('total_amount'))\n",
    "print(tx_per_client.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5115bc3b",
   "metadata": {},
   "source": [
    "## 5. Joining DataFrames\n",
    "\n",
    "Combine information from different tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa933c4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:08.571810Z",
     "iopub.status.busy": "2025-04-21T17:01:08.571039Z",
     "iopub.status.idle": "2025-04-21T17:01:08.610760Z",
     "shell.execute_reply": "2025-04-21T17:01:08.608289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Join clients and transactions\n",
    "joined = clients.join(tx_per_client, on='client_id', how='left')\n",
    "print(joined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791461b",
   "metadata": {},
   "source": [
    "## 6. Advanced Analysis: Window Functions\n",
    "\n",
    "Calculate running totals and rankings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f585e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:08.626459Z",
     "iopub.status.busy": "2025-04-21T17:01:08.625664Z",
     "iopub.status.idle": "2025-04-21T17:01:08.690488Z",
     "shell.execute_reply": "2025-04-21T17:01:08.687457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Running total of transactions per client\n",
    "transactions_sorted = transactions.sort(['client_id', 'date'])\n",
    "transactions_with_cumsum = transactions_sorted.with_columns(\n",
    "    pl.col('amount').cum_sum().over('client_id').alias('running_total')\n",
    ")\n",
    "print(transactions_with_cumsum.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ed2d5c",
   "metadata": {},
   "source": [
    "## 7. Pivoting and Reshaping Data\n",
    "\n",
    "Turn long data into wide, or vice versa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ae573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:08.704640Z",
     "iopub.status.busy": "2025-04-21T17:01:08.702499Z",
     "iopub.status.idle": "2025-04-21T17:01:08.746966Z",
     "shell.execute_reply": "2025-04-21T17:01:08.739670Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pivot: total amount per client per transaction type\n",
    "pivot = transactions.pivot(\n",
    "    values='amount',\n",
    "    index='client_id',\n",
    "    on='asset_id',  # replace with an actual column name\n",
    "    aggregate_function='sum'\n",
    ")\n",
    "print(pivot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81593ce",
   "metadata": {},
   "source": [
    "## 8. SQL Queries in Polars\n",
    "\n",
    "Polars supports SQL for those familiar with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab7ca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:08.763262Z",
     "iopub.status.busy": "2025-04-21T17:01:08.762654Z",
     "iopub.status.idle": "2025-04-21T17:01:08.808415Z",
     "shell.execute_reply": "2025-04-21T17:01:08.802291Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = pl.SQLContext()\n",
    "ctx.register('transactions', transactions)\n",
    "sql_result = ctx.execute(\"SELECT client_id, SUM(amount) as total FROM transactions GROUP BY client_id ORDER BY total DESC\").collect()\n",
    "print(sql_result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ca041",
   "metadata": {},
   "source": [
    "## 9. Handling Missing Data\n",
    "\n",
    "Polars makes it easy to find and fill missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa2436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:08.825902Z",
     "iopub.status.busy": "2025-04-21T17:01:08.825000Z",
     "iopub.status.idle": "2025-04-21T17:01:08.862560Z",
     "shell.execute_reply": "2025-04-21T17:01:08.860484Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(transactions.null_count())\n",
    "# Fill missing values (if any)\n",
    "filled = transactions.fill_null(0)\n",
    "print(filled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f73990d",
   "metadata": {},
   "source": [
    "## 10. Exporting Data\n",
    "\n",
    "Save your results for use elsewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9febaac4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:08.874459Z",
     "iopub.status.busy": "2025-04-21T17:01:08.873496Z",
     "iopub.status.idle": "2025-04-21T17:01:08.890365Z",
     "shell.execute_reply": "2025-04-21T17:01:08.886883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "tx_per_client.write_csv('tx_per_client.csv')\n",
    "print('Exported tx_per_client.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdfd20b",
   "metadata": {},
   "source": [
    "## Real-Life Wealth Management Scenario: Delivering Strategic Insights\n",
    "\n",
    "**Scenario:**  \n",
    "Your employer, a wealth management firm, asks you to deliver a comprehensive analysis of client portfolio performance, risk exposure, and investment trends. The goal is to identify high-value clients, assess risk-adjusted returns, and uncover actionable insights for strategic decision-making.\n",
    "\n",
    "You have access to the following datasets:\n",
    "- `clients.csv`: Client demographic and onboarding data\n",
    "- `transactions.csv`: All buy/sell trades per client\n",
    "- `assets.parquet`: Asset metadata (type, region, risk)\n",
    "- `portfolio_performance.csv`: Daily portfolio values and returns\n",
    "\n",
    "**Your task:**  \n",
    "1. Integrate all datasets to create a unified view of each client's investment journey.\n",
    "2. Clean and enrich the data (handle missing values, standardize types, join relevant info).\n",
    "3. Analyze portfolio performance, risk, and client behavior.\n",
    "4. Deliver actionable insights for the business.\n",
    "\n",
    "Let's see how Polars enables you to go above and beyond in this scenario!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d5e1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:01:08.909079Z",
     "iopub.status.busy": "2025-04-21T17:01:08.906495Z",
     "iopub.status.idle": "2025-04-21T17:01:09.188558Z",
     "shell.execute_reply": "2025-04-21T17:01:09.186235Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Wealth Management Data Analysis: Robust, Transparent, and Maintainable Polars Workflow ---\n",
    "\n",
    "import polars as pl\n",
    "import os\n",
    "\n",
    "# --- 1. Data Loading with Diagnostics and Error Handling ---\n",
    "\n",
    "def safe_read_csv(path, **kwargs):\n",
    "    \"\"\"Safely read a CSV file and provide diagnostics if missing.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: File not found: {path}\")\n",
    "        return None\n",
    "    df = pl.read_csv(path, **kwargs)\n",
    "    print(f\"Loaded {path} with shape {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def safe_read_parquet(path, **kwargs):\n",
    "    \"\"\"Safely read a Parquet file and provide diagnostics if missing.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: File not found: {path}\")\n",
    "        return None\n",
    "    df = pl.read_parquet(path, **kwargs)\n",
    "    print(f\"Loaded {path} with shape {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# Load datasets with clear paths (update paths as needed)\n",
    "clients = safe_read_csv('../datasets/clients.csv')\n",
    "transactions = safe_read_csv('../datasets/transactions.csv')\n",
    "assets = safe_read_parquet('../datasets/assets.parquet')\n",
    "portfolio = safe_read_csv('../datasets/portfolio_performance.csv')\n",
    "\n",
    "# --- 2. Data Cleaning & Enrichment: Defensive Datetime Parsing ---\n",
    "\n",
    "def parse_datetime_column(df, col, fmt, strict=False):\n",
    "    \"\"\"Parse a column as datetime if it exists, with diagnostics.\"\"\"\n",
    "    if df is not None and col in df.columns:\n",
    "        print(f\"Parsing '{col}' in DataFrame with format '{fmt}' (strict={strict})\")\n",
    "        return df.with_columns(\n",
    "            pl.col(col).str.strptime(pl.Datetime, fmt, strict=strict)\n",
    "        )\n",
    "    elif df is not None:\n",
    "        print(f\"Warning: '{col}' column not found in DataFrame. Skipping datetime parsing.\")\n",
    "    return df\n",
    "\n",
    "# Parse date columns with robust handling of possible formats\n",
    "clients = parse_datetime_column(clients, \"join_date\", \"%Y-%m-%dT%H:%M:%S%.f\", strict=False)\n",
    "transactions = parse_datetime_column(transactions, \"date\", \"%Y-%m-%dT%H:%M:%S%.f\", strict=False)\n",
    "\n",
    "# --- Robust Portfolio Date Parsing ---\n",
    "if portfolio is not None:\n",
    "    print(\"Portfolio columns before date parsing:\", portfolio.columns)\n",
    "    # Try to parse 'date' column if present\n",
    "    if \"date\" in portfolio.columns:\n",
    "        portfolio = parse_datetime_column(portfolio, \"date\", \"%Y-%m-%d\")\n",
    "        print(\"Parsed 'date' column in portfolio as datetime.\")\n",
    "    # Otherwise, try to parse 'trade_date' (common in financial datasets)\n",
    "    elif \"trade_date\" in portfolio.columns:\n",
    "        portfolio = parse_datetime_column(portfolio, \"trade_date\", \"%Y-%m-%d\")\n",
    "        print(\"Parsed 'trade_date' column in portfolio as datetime.\")\n",
    "    else:\n",
    "        print(\"Warning: No suitable date column ('date' or 'trade_date') found in portfolio. Available columns:\", portfolio.columns)\n",
    "    # Show a preview of the parsed portfolio\n",
    "    print(\"Sample of portfolio DataFrame after date parsing:\")\n",
    "    print(portfolio.head())\n",
    "\n",
    "# --- 3. Data Integration: Robust Joins with Diagnostics ---\n",
    "\n",
    "# Join transactions with asset metadata\n",
    "if transactions is not None and assets is not None:\n",
    "    tx_assets = transactions.join(assets, left_on=\"asset_id\", right_on=\"asset_id\", how=\"left\")\n",
    "    print(\"Joined transactions with assets. Result shape:\", tx_assets.shape)\n",
    "else:\n",
    "    tx_assets = None\n",
    "    print(\"Warning: Could not join transactions with assets due to missing data.\")\n",
    "\n",
    "# Join with client info\n",
    "if tx_assets is not None and clients is not None:\n",
    "    tx_full = tx_assets.join(clients, left_on=\"client_id\", right_on=\"client_id\", how=\"left\")\n",
    "    print(\"Joined tx_assets with clients. Result shape:\", tx_full.shape)\n",
    "else:\n",
    "    tx_full = None\n",
    "    print(\"Warning: Could not join tx_assets with clients due to missing data.\")\n",
    "\n",
    "# --- 4. Analysis 1: Identify High-Value Clients ---\n",
    "\n",
    "if tx_full is not None:\n",
    "    print(\"tx_full columns:\", tx_full.columns)\n",
    "    # Defensive aggregation: check for risk_score or fallback to just amount/num_trades\n",
    "    if \"risk_score\" in tx_full.columns:\n",
    "        total_invested = (\n",
    "            tx_full\n",
    "            .group_by(\"client_id\")\n",
    "            .agg([\n",
    "                pl.col(\"amount\").sum().alias(\"total_invested\"),\n",
    "                pl.col(\"amount\").count().alias(\"num_trades\"),\n",
    "                pl.col(\"risk_score\").mean().alias(\"avg_risk_score\")\n",
    "            ])\n",
    "            .sort(\"total_invested\", descending=True)\n",
    "        )\n",
    "    elif \"risk\" in tx_full.columns:\n",
    "        total_invested = (\n",
    "            tx_full\n",
    "            .group_by(\"client_id\")\n",
    "            .agg([\n",
    "                pl.col(\"amount\").sum().alias(\"total_invested\"),\n",
    "                pl.col(\"amount\").count().alias(\"num_trades\"),\n",
    "                pl.col(\"risk\").mean().alias(\"avg_risk_score\")\n",
    "            ])\n",
    "            .sort(\"total_invested\", descending=True)\n",
    "        )\n",
    "        print(\"Warning: Used 'risk' column instead of 'risk_score'.\")\n",
    "    else:\n",
    "        total_invested = (\n",
    "            tx_full\n",
    "            .group_by(\"client_id\")\n",
    "            .agg([\n",
    "                pl.col(\"amount\").sum().alias(\"total_invested\"),\n",
    "                pl.col(\"amount\").count().alias(\"num_trades\"),\n",
    "            ])\n",
    "            .sort(\"total_invested\", descending=True)\n",
    "        )\n",
    "        print(\"Warning: No risk_score or risk column found. Only aggregating invested amount and trade count.\")\n",
    "\n",
    "    print(\"\\nTop 5 High-Value Clients:\")\n",
    "    print(total_invested.head(5))\n",
    "else:\n",
    "    print(\"Analysis 1 skipped: tx_full is None.\")\n",
    "\n",
    "# --- 5. Analysis 2: Portfolio Risk-Adjusted Returns ---\n",
    "\n",
    "if portfolio is not None and clients is not None and \"client_id\" in portfolio.columns:\n",
    "    # Join portfolio with clients for demographic analysis\n",
    "    portfolio_clients = portfolio.join(clients, on=\"client_id\", how=\"left\")\n",
    "    # Calculate risk-adjusted return (Sharpe ratio proxy: mean return / stddev)\n",
    "    # Defensive: check for daily_return or daily_return_pct\n",
    "    if \"daily_return\" in portfolio_clients.columns:\n",
    "        mean_col = \"daily_return\"\n",
    "    elif \"daily_return_pct\" in portfolio_clients.columns:\n",
    "        mean_col = \"daily_return_pct\"\n",
    "    else:\n",
    "        mean_col = None\n",
    "\n",
    "    if mean_col:\n",
    "        risk_adj = (\n",
    "            portfolio_clients\n",
    "            .group_by(\"client_id\")\n",
    "            .agg([\n",
    "                pl.col(mean_col).mean().alias(\"mean_return\"),\n",
    "                pl.col(mean_col).std().alias(\"std_return\"),\n",
    "                (pl.col(mean_col).mean() / pl.col(mean_col).std()).alias(\"risk_adjusted_return\")\n",
    "            ])\n",
    "            .sort(\"risk_adjusted_return\", descending=True)\n",
    "        )\n",
    "        print(\"\\nTop 5 Clients by Risk-Adjusted Return:\")\n",
    "        print(risk_adj.head(5))\n",
    "    else:\n",
    "        print(\"Analysis 2 skipped: No daily return column found in portfolio.\")\n",
    "else:\n",
    "    print(\"Analysis 2 skipped: Required columns missing in portfolio or clients.\")\n",
    "\n",
    "# --- 6. Analysis 3: Investment Trends by Asset Type & Region ---\n",
    "\n",
    "if tx_full is not None and \"asset_type\" in tx_full.columns and \"region\" in tx_full.columns:\n",
    "    trend = (\n",
    "        tx_full\n",
    "        .group_by([\"asset_type\", \"region\"])\n",
    "        .agg([\n",
    "            pl.col(\"amount\").sum().alias(\"total_invested\"),\n",
    "            pl.col(\"client_id\").n_unique().alias(\"unique_clients\")\n",
    "        ])\n",
    "        .sort(\"total_invested\", descending=True)\n",
    "    )\n",
    "    print(\"\\nTop Investment Trends (by Asset Type & Region):\")\n",
    "    print(trend.head(10))\n",
    "else:\n",
    "    print(\"Analysis 3 skipped: 'asset_type' or 'region' column missing in tx_full.\")\n",
    "\n",
    "# --- 7. Actionable Insights: Flag Clients with High Risk and Low Diversification ---\n",
    "\n",
    "if tx_full is not None:\n",
    "    # Use risk_score or risk if available\n",
    "    risk_col = \"risk_score\" if \"risk_score\" in tx_full.columns else (\"risk\" if \"risk\" in tx_full.columns else None)\n",
    "    if risk_col:\n",
    "        diversification = (\n",
    "            tx_full\n",
    "            .group_by(\"client_id\")\n",
    "            .agg([\n",
    "                pl.col(\"asset_id\").n_unique().alias(\"num_assets\"),\n",
    "                pl.col(risk_col).mean().alias(\"avg_risk_score\")\n",
    "            ])\n",
    "            .filter((pl.col(\"num_assets\") < 3) & (pl.col(\"avg_risk_score\") > 7))\n",
    "        )\n",
    "        print(\"\\nClients with High Risk and Low Diversification:\")\n",
    "        print(diversification)\n",
    "    else:\n",
    "        print(\"Actionable insights skipped: No risk_score or risk column found in tx_full.\")\n",
    "else:\n",
    "    print(\"Actionable insights skipped: tx_full is None.\")\n",
    "\n",
    "# --- 8. Best Practices & Next Steps ---\n",
    "# - Always review printed diagnostics for missing data or schema mismatches.\n",
    "# - If you add new datasets or columns, update the parsing and join logic accordingly.\n",
    "# - For large datasets, consider lazy evaluation (pl.scan_csv, pl.scan_parquet) for performance.\n",
    "# - Document any business logic assumptions at the top of your notebook for future users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2873c57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "This workbook has shown how to use Polars for a wide range of data analysis tasks, from loading and exploring data, to advanced analytics and exporting results. All examples use real datasets and are explained in simple terms.\n",
    "\n",
    "For more, see the other notebooks in this project!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
